{
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "# Load necessary packages\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split, learning_curve\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn import metrics\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "collapsed": false,
        "outputHidden": false,
        "inputHidden": false
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Load Data & Split Train-Test sets\n",
        "url = ''\n",
        "lead_score = pd.read_csv(url, sep=\",\")\n",
        "X = lead_score.ix[:, lead_score.columns != 'qualified']\n",
        "y = lead_score.iloc[:,-1]\n",
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "    X, y, test_size=0.33, random_state=42)"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "collapsed": false,
        "outputHidden": true,
        "inputHidden": false
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Implement Logistic Regression\n",
        "logistic = LogisticRegression()\n",
        "logistic.fit(X_train,y_train)"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "collapsed": false,
        "outputHidden": false,
        "inputHidden": false
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Make predictions on the test set\n",
        "predictions = logistic.predict(X_test)\n",
        "prediction_proba = logistic.predict_proba(X_test)\n",
        "y_pred = logistic.predict(X_train)"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "collapsed": false,
        "outputHidden": false,
        "inputHidden": false
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Compute evaluation Metrics\n",
        "print(\"Accuracy: %2f\" % metrics.accuracy_score(y_train, y_pred))\n",
        "print(\"Precision: %2f\" % metrics.precision_score(y_train, y_pred, average=\"macro\"))\n",
        "print(\"F1: %2f\" % metrics.f1_score(y_train, y_pred, average=\"macro\"))\n",
        "metrics.confusion_matrix(y_test, predictions)"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "collapsed": false,
        "outputHidden": false,
        "inputHidden": false
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "collapsed": false,
        "outputHidden": false,
        "inputHidden": false
      }
    }
  ],
  "metadata": {
    "kernel_info": {
      "name": "python3"
    },
    "kernelspec": {
      "name": "python3",
      "language": "python",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python",
      "version": "3.6.1",
      "mimetype": "text/x-python",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "file_extension": ".py"
    },
    "nteract": {
      "version": "0.8.4"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 4
}